{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "Zpq4QOU5Wg-H",
    "i_7DyyXRWg-K",
    "_JewKs4XU-so",
    "5yiLk1P_xYQ2",
    "VlWxW3e9Wg-m",
    "D39SSh0zWg-r",
    "rhVrgkSaWg_K",
    "XsRf9T_SWg_U",
    "ylKZG2MwWg_f",
    "9hedBdcYWhAH",
    "JrqW55jgWhAR",
    "5QYTwyMtWhAZ",
    "DbJrUpARWhAd",
    "MI18l-l9WhAk",
    "1wrEGqBSWhAr",
    "gStgBJy2WhAx"
   ],
   "include_colab_link": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Patisson4/ML/blob/lab-5/lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHX9p5jfTySS"
   },
   "source": [
    "## Задание 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EnHNZtbXlH0"
   },
   "source": [
    "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mdpol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mdpol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "data = pd.read_csv(\n",
    "    'https://github.com/sismetanin/rureviews/blob/master/women-clothing-accessories.3-class.balanced.csv?raw=true',\n",
    "    sep='\\t')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import string\n",
    "from time import perf_counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data['format'] = data['review']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJox-LoonoPx"
   },
   "source": [
    "Применим полученные навыки и решим задачу анализа тональности отзывов. \n",
    "\n",
    "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
    "\n",
    "Обязательные шаги предобработки:\n",
    "1. токенизация\n",
    "2. приведение к нижнему регистру\n",
    "3. удаление стоп-слов\n",
    "4. лемматизация\n",
    "5. векторизация (с настройкой гиперпараметров)\n",
    "6. построение модели\n",
    "7. оценка качества модели\n",
    "\n",
    "Обязательно использование векторайзеров:\n",
    "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
    "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать гиперпараметры max_df, min_df, max_features)\n",
    "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
    "\n",
    "В качестве классификатора нужно использовать наивный байесовский классификатор. \n",
    "\n",
    "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review sentiment  \\\n",
      "0  качество плохое пошив ужасный (горловина напер...  negative   \n",
      "1  Товар отдали другому человеку, я не получила п...  negative   \n",
      "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
      "3  товар не пришел, продавец продлил защиту без м...  negative   \n",
      "4      Кофточка голая синтетика, носить не возможно.  negative   \n",
      "5                              Очень глубокие проймы  negative   \n",
      "6  Я недовольна заказом.Я вот одного не понимаю п...  negative   \n",
      "7  заказала размер s на от 64,об 94,начнем с того...  negative   \n",
      "8  Заказ я сделала в июле. С тех пор посылка отсл...  negative   \n",
      "9                           Ужасное качество товара!  negative   \n",
      "\n",
      "                                              format  \n",
      "0  качество плохой пошив ужасный горловина напере...  \n",
      "1  товар отдать другой человек я не получить посы...  \n",
      "2  ужасный синтетик тонкий ничего общий с предста...  \n",
      "3  товар не прийти продавец продлить защита без м...  \n",
      "4         кофточка голый синтетик носить не возможно  \n",
      "5                              очень глубокий пройма  \n",
      "6  я недовольный заказомить вот один не понимать ...  \n",
      "7  заказать размер s на от 64об 94начать с тот чт...  \n",
      "8  заказ я сделать в июль с тот пора посылка отсл...  \n",
      "9                             ужасный качество товар  \n",
      "Performed in 996.9023884999915\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "\n",
    "analyzer = MorphAnalyzer()\n",
    "\n",
    "for i in range(len(data)):\n",
    "    for pun in string.punctuation:\n",
    "        data.format[i] = data.format[i].replace(pun, \" \")\n",
    "    tokens = [analyzer.parse(word.lower())[0].normal_form for word in word_tokenize(data.format[i])]\n",
    "    data.format[i] = \" \".join(tokens)\n",
    "\n",
    "print(data.head(10))\n",
    "print(f'Performed in {perf_counter() - start}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "results = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.format, data.sentiment, train_size=0.7)\n",
    "\n",
    "def naive_bayes_classifier(vectorizer):\n",
    "    started = perf_counter()\n",
    "\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(vectorizer.fit_transform(X_train), y_train)\n",
    "\n",
    "    predicted = classifier.predict(vectorizer.transform(X_test))\n",
    "    results.append([classification_report(y_test, predicted, output_dict=True, zero_division=0), vectorizer])\n",
    "\n",
    "    print(f\"ngram_range: {vectorizer.ngram_range}\", f\"analyzer: {vectorizer.analyzer}\", classification_report(y_test, predicted, output_dict=False, zero_division=0), sep='\\n')\n",
    "    print(f\"Performed in {perf_counter() - started}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.58      0.57      8957\n",
      "    negative       0.70      0.64      0.67      9045\n",
      "    positive       0.77      0.80      0.79      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.68      0.67      0.67     27001\n",
      "weighted avg       0.68      0.67      0.67     27001\n",
      "\n",
      "Performed in 5.29684600001201\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.56      0.56      8957\n",
      "    negative       0.69      0.65      0.67      9045\n",
      "    positive       0.76      0.80      0.78      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.67      0.67      0.67     27001\n",
      "weighted avg       0.67      0.67      0.67     27001\n",
      "\n",
      "Performed in 8.560886099992786\n",
      "ngram_range: (2, 4)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.56      0.56      8957\n",
      "    negative       0.69      0.66      0.67      9045\n",
      "    positive       0.76      0.80      0.78      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.67      0.67      0.67     27001\n",
      "weighted avg       0.67      0.67      0.67     27001\n",
      "\n",
      "Performed in 13.853698899998562\n",
      "ngram_range: (2, 5)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.56      0.56      8957\n",
      "    negative       0.69      0.66      0.67      9045\n",
      "    positive       0.76      0.80      0.78      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.67      0.67      0.67     27001\n",
      "weighted avg       0.67      0.67      0.67     27001\n",
      "\n",
      "Performed in 17.234022300021024\n",
      "ngram_range: (2, 6)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.55      0.56      8957\n",
      "    negative       0.69      0.66      0.67      9045\n",
      "    positive       0.76      0.80      0.78      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.67      0.67      0.67     27001\n",
      "weighted avg       0.67      0.67      0.67     27001\n",
      "\n",
      "Performed in 22.60226529999636\n",
      "ngram_range: (2, 7)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.55      0.56      8957\n",
      "    negative       0.69      0.66      0.67      9045\n",
      "    positive       0.76      0.80      0.78      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.67      0.67      0.67     27001\n",
      "weighted avg       0.67      0.67      0.67     27001\n",
      "\n",
      "Performed in 25.51515130000189\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.43      0.61      0.51      8957\n",
      "    negative       0.67      0.50      0.57      9045\n",
      "    positive       0.69      0.59      0.64      8999\n",
      "\n",
      "    accuracy                           0.57     27001\n",
      "   macro avg       0.60      0.57      0.57     27001\n",
      "weighted avg       0.60      0.57      0.57     27001\n",
      "\n",
      "Performed in 5.882597000017995\n",
      "ngram_range: (3, 4)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.43      0.61      0.51      8957\n",
      "    negative       0.67      0.50      0.57      9045\n",
      "    positive       0.69      0.59      0.64      8999\n",
      "\n",
      "    accuracy                           0.57     27001\n",
      "   macro avg       0.60      0.57      0.57     27001\n",
      "weighted avg       0.60      0.57      0.57     27001\n",
      "\n",
      "Performed in 15.083389300009003\n",
      "ngram_range: (3, 5)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.43      0.61      0.51      8957\n",
      "    negative       0.67      0.50      0.57      9045\n",
      "    positive       0.69      0.59      0.63      8999\n",
      "\n",
      "    accuracy                           0.57     27001\n",
      "   macro avg       0.60      0.57      0.57     27001\n",
      "weighted avg       0.60      0.57      0.57     27001\n",
      "\n",
      "Performed in 15.246488900011173\n",
      "ngram_range: (3, 6)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.43      0.61      0.51      8957\n",
      "    negative       0.67      0.50      0.57      9045\n",
      "    positive       0.69      0.59      0.63      8999\n",
      "\n",
      "    accuracy                           0.57     27001\n",
      "   macro avg       0.60      0.57      0.57     27001\n",
      "weighted avg       0.60      0.57      0.57     27001\n",
      "\n",
      "Performed in 21.703973199997563\n",
      "ngram_range: (3, 7)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.43      0.61      0.51      8957\n",
      "    negative       0.67      0.50      0.57      9045\n",
      "    positive       0.69      0.59      0.63      8999\n",
      "\n",
      "    accuracy                           0.57     27001\n",
      "   macro avg       0.60      0.57      0.57     27001\n",
      "weighted avg       0.60      0.57      0.57     27001\n",
      "\n",
      "Performed in 29.71858610000345\n",
      "ngram_range: (4, 4)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.37      0.83      0.51      8957\n",
      "    negative       0.70      0.27      0.39      9045\n",
      "    positive       0.70      0.25      0.37      8999\n",
      "\n",
      "    accuracy                           0.45     27001\n",
      "   macro avg       0.59      0.45      0.42     27001\n",
      "weighted avg       0.59      0.45      0.42     27001\n",
      "\n",
      "Performed in 8.833989299979294\n",
      "ngram_range: (4, 5)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.37      0.83      0.51      8957\n",
      "    negative       0.70      0.27      0.39      9045\n",
      "    positive       0.70      0.25      0.37      8999\n",
      "\n",
      "    accuracy                           0.45     27001\n",
      "   macro avg       0.59      0.45      0.42     27001\n",
      "weighted avg       0.59      0.45      0.42     27001\n",
      "\n",
      "Performed in 10.566089800006012\n",
      "ngram_range: (4, 6)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.37      0.83      0.51      8957\n",
      "    negative       0.70      0.27      0.39      9045\n",
      "    positive       0.70      0.25      0.37      8999\n",
      "\n",
      "    accuracy                           0.45     27001\n",
      "   macro avg       0.59      0.45      0.42     27001\n",
      "weighted avg       0.59      0.45      0.42     27001\n",
      "\n",
      "Performed in 15.93894469999941\n",
      "ngram_range: (4, 7)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.37      0.83      0.51      8957\n",
      "    negative       0.70      0.27      0.39      9045\n",
      "    positive       0.70      0.25      0.37      8999\n",
      "\n",
      "    accuracy                           0.45     27001\n",
      "   macro avg       0.59      0.45      0.42     27001\n",
      "weighted avg       0.59      0.45      0.42     27001\n",
      "\n",
      "Performed in 17.65125250001438\n",
      "ngram_range: (5, 5)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.34      0.96      0.50      8957\n",
      "    negative       0.74      0.10      0.17      9045\n",
      "    positive       0.71      0.05      0.09      8999\n",
      "\n",
      "    accuracy                           0.37     27001\n",
      "   macro avg       0.60      0.37      0.25     27001\n",
      "weighted avg       0.60      0.37      0.25     27001\n",
      "\n",
      "Performed in 6.070427900005598\n",
      "ngram_range: (5, 6)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.34      0.96      0.50      8957\n",
      "    negative       0.74      0.10      0.17      9045\n",
      "    positive       0.71      0.05      0.09      8999\n",
      "\n",
      "    accuracy                           0.37     27001\n",
      "   macro avg       0.60      0.37      0.25     27001\n",
      "weighted avg       0.60      0.37      0.25     27001\n",
      "\n",
      "Performed in 10.81218209999497\n",
      "ngram_range: (5, 7)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.34      0.96      0.50      8957\n",
      "    negative       0.74      0.10      0.17      9045\n",
      "    positive       0.71      0.05      0.09      8999\n",
      "\n",
      "    accuracy                           0.37     27001\n",
      "   macro avg       0.60      0.37      0.25     27001\n",
      "weighted avg       0.60      0.37      0.25     27001\n",
      "\n",
      "Performed in 11.184598699997878\n",
      "ngram_range: (6, 6)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.81      0.03      0.06      9045\n",
      "    positive       0.74      0.01      0.02      8999\n",
      "\n",
      "    accuracy                           0.34     27001\n",
      "   macro avg       0.63      0.34      0.19     27001\n",
      "weighted avg       0.63      0.34      0.19     27001\n",
      "\n",
      "Performed in 6.373088500025915\n",
      "ngram_range: (6, 7)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.82      0.03      0.06      9045\n",
      "    positive       0.74      0.01      0.02      8999\n",
      "\n",
      "    accuracy                           0.34     27001\n",
      "   macro avg       0.63      0.34      0.19     27001\n",
      "weighted avg       0.63      0.34      0.19     27001\n",
      "\n",
      "Performed in 12.979249700001674\n",
      "ngram_range: (7, 7)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      1.00      0.50      8957\n",
      "    negative       0.90      0.01      0.02      9045\n",
      "    positive       0.78      0.00      0.00      8999\n",
      "\n",
      "    accuracy                           0.34     27001\n",
      "   macro avg       0.67      0.34      0.18     27001\n",
      "weighted avg       0.67      0.34      0.17     27001\n",
      "\n",
      "Performed in 5.250759199989261\n"
     ]
    }
   ],
   "source": [
    "MIN_NGRAM = 2\n",
    "MAX_NGRAM = 8\n",
    "\n",
    "for min_n in range(MIN_NGRAM, MAX_NGRAM):\n",
    "    for max_n in range(min_n, MAX_NGRAM):\n",
    "        naive_bayes_classifier(CountVectorizer(ngram_range=(min_n, max_n), stop_words=stopwords.words('russian')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.47      0.68      0.55      8957\n",
      "    negative       0.72      0.50      0.59      9045\n",
      "    positive       0.74      0.63      0.68      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.61     27001\n",
      "weighted avg       0.64      0.60      0.61     27001\n",
      "\n",
      "Performed in 8.215002400014782\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.54      0.64      0.58      8957\n",
      "    negative       0.71      0.60      0.65      9045\n",
      "    positive       0.79      0.76      0.77      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.68      0.67      0.67     27001\n",
      "weighted avg       0.68      0.67      0.67     27001\n",
      "\n",
      "Performed in 5.877623000007588\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.54      0.62      0.58      8957\n",
      "    negative       0.71      0.62      0.66      9045\n",
      "    positive       0.78      0.77      0.78      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.68      0.67      0.67     27001\n",
      "weighted avg       0.68      0.67      0.67     27001\n",
      "\n",
      "Performed in 5.629284700000426\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.69      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.74      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 5.889705100009451\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.69      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.74      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 5.177198999997927\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.69      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.74      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 6.185088700003689\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 6.13782689999789\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 4.697469100006856\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 5.119306100008544\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.47      0.68      0.55      8957\n",
      "    negative       0.72      0.50      0.59      9045\n",
      "    positive       0.74      0.63      0.68      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.61     27001\n",
      "weighted avg       0.64      0.60      0.61     27001\n",
      "\n",
      "Performed in 6.720182299992302\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.54      0.64      0.58      8957\n",
      "    negative       0.71      0.60      0.65      9045\n",
      "    positive       0.79      0.76      0.77      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.68      0.67      0.67     27001\n",
      "weighted avg       0.68      0.67      0.67     27001\n",
      "\n",
      "Performed in 7.797977499983972\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.54      0.62      0.58      8957\n",
      "    negative       0.71      0.62      0.66      9045\n",
      "    positive       0.78      0.77      0.78      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.68      0.67      0.67     27001\n",
      "weighted avg       0.68      0.67      0.67     27001\n",
      "\n",
      "Performed in 5.874784699990414\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.69      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.74      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 4.498285399982706\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.69      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.74      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 4.41371789999539\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.69      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.74      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 5.303316600009566\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 4.3334045999799855\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 4.126411500008544\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (2, 2)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 4.656610799982445\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 8.119793899997603\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.53      0.65      0.58      8957\n",
      "    negative       0.72      0.59      0.65      9045\n",
      "    positive       0.78      0.75      0.77      8999\n",
      "\n",
      "    accuracy                           0.66     27001\n",
      "   macro avg       0.68      0.66      0.67     27001\n",
      "weighted avg       0.68      0.66      0.67     27001\n",
      "\n",
      "Performed in 8.485861400025897\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.54      0.63      0.58      8957\n",
      "    negative       0.72      0.61      0.66      9045\n",
      "    positive       0.78      0.77      0.77      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.68      0.67      0.67     27001\n",
      "weighted avg       0.68      0.67      0.67     27001\n",
      "\n",
      "Performed in 9.125539500004379\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 8.508056199993007\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 7.930846200004453\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 8.335334200004581\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 8.442114200006472\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 8.632658699993044\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 9.521344699984184\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 8.591713599977084\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.53      0.65      0.58      8957\n",
      "    negative       0.72      0.59      0.65      9045\n",
      "    positive       0.78      0.75      0.77      8999\n",
      "\n",
      "    accuracy                           0.66     27001\n",
      "   macro avg       0.68      0.66      0.67     27001\n",
      "weighted avg       0.68      0.66      0.67     27001\n",
      "\n",
      "Performed in 8.537948499986669\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.54      0.63      0.58      8957\n",
      "    negative       0.72      0.61      0.66      9045\n",
      "    positive       0.78      0.77      0.77      8999\n",
      "\n",
      "    accuracy                           0.67     27001\n",
      "   macro avg       0.68      0.67      0.67     27001\n",
      "weighted avg       0.68      0.67      0.67     27001\n",
      "\n",
      "Performed in 8.055027800000971\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 8.28967399999965\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 7.828551900020102\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.46      0.68      0.55      8957\n",
      "    negative       0.72      0.49      0.59      9045\n",
      "    positive       0.73      0.62      0.67      8999\n",
      "\n",
      "    accuracy                           0.60     27001\n",
      "   macro avg       0.64      0.60      0.60     27001\n",
      "weighted avg       0.64      0.60      0.60     27001\n",
      "\n",
      "Performed in 7.9598819999955595\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 8.207044300012058\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 8.766677799983881\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (2, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.38      0.80      0.52      8957\n",
      "    negative       0.72      0.30      0.42      9045\n",
      "    positive       0.67      0.32      0.43      8999\n",
      "\n",
      "    accuracy                           0.47     27001\n",
      "   macro avg       0.59      0.47      0.46     27001\n",
      "weighted avg       0.59      0.47      0.46     27001\n",
      "\n",
      "Performed in 10.126748799986672\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.37      0.84      0.52      8957\n",
      "    negative       0.74      0.28      0.40      9045\n",
      "    positive       0.71      0.27      0.39      8999\n",
      "\n",
      "    accuracy                           0.46     27001\n",
      "   macro avg       0.61      0.46      0.44     27001\n",
      "weighted avg       0.61      0.46      0.44     27001\n",
      "\n",
      "Performed in 5.596536600001855\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.41      0.72      0.52      8957\n",
      "    negative       0.70      0.42      0.52      9045\n",
      "    positive       0.72      0.48      0.57      8999\n",
      "\n",
      "    accuracy                           0.54     27001\n",
      "   macro avg       0.61      0.54      0.54     27001\n",
      "weighted avg       0.61      0.54      0.54     27001\n",
      "\n",
      "Performed in 5.6291641000134405\n",
      "min_df: 0; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.42      0.70      0.52      8957\n",
      "    negative       0.69      0.45      0.54      9045\n",
      "    positive       0.72      0.51      0.60      8999\n",
      "\n",
      "    accuracy                           0.55     27001\n",
      "   macro avg       0.61      0.55      0.55     27001\n",
      "weighted avg       0.61      0.55      0.55     27001\n",
      "\n",
      "Performed in 5.960194099985529\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.35      0.91      0.50      8957\n",
      "    negative       0.76      0.16      0.27      9045\n",
      "    positive       0.62      0.11      0.18      8999\n",
      "\n",
      "    accuracy                           0.39     27001\n",
      "   macro avg       0.58      0.40      0.32     27001\n",
      "weighted avg       0.58      0.39      0.32     27001\n",
      "\n",
      "Performed in 5.772925600002054\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.35      0.91      0.50      8957\n",
      "    negative       0.76      0.16      0.27      9045\n",
      "    positive       0.62      0.11      0.18      8999\n",
      "\n",
      "    accuracy                           0.39     27001\n",
      "   macro avg       0.58      0.40      0.32     27001\n",
      "weighted avg       0.58      0.39      0.32     27001\n",
      "\n",
      "Performed in 6.122948000003817\n",
      "min_df: 0.001; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.35      0.91      0.50      8957\n",
      "    negative       0.76      0.16      0.27      9045\n",
      "    positive       0.62      0.11      0.18      8999\n",
      "\n",
      "    accuracy                           0.39     27001\n",
      "   macro avg       0.58      0.40      0.32     27001\n",
      "weighted avg       0.58      0.39      0.32     27001\n",
      "\n",
      "Performed in 5.66330939999898\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.00      0.00      0.00      9045\n",
      "    positive       0.06      0.00      0.00      8999\n",
      "\n",
      "    accuracy                           0.33     27001\n",
      "   macro avg       0.13      0.33      0.17     27001\n",
      "weighted avg       0.13      0.33      0.17     27001\n",
      "\n",
      "Performed in 5.8938794000132475\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.00      0.00      0.00      9045\n",
      "    positive       0.06      0.00      0.00      8999\n",
      "\n",
      "    accuracy                           0.33     27001\n",
      "   macro avg       0.13      0.33      0.17     27001\n",
      "weighted avg       0.13      0.33      0.17     27001\n",
      "\n",
      "Performed in 6.368060899985721\n",
      "min_df: 0.01; max_df: 0.1\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.00      0.00      0.00      9045\n",
      "    positive       0.06      0.00      0.00      8999\n",
      "\n",
      "    accuracy                           0.33     27001\n",
      "   macro avg       0.13      0.33      0.17     27001\n",
      "weighted avg       0.13      0.33      0.17     27001\n",
      "\n",
      "Performed in 5.718521400005557\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.37      0.84      0.52      8957\n",
      "    negative       0.74      0.28      0.40      9045\n",
      "    positive       0.71      0.27      0.39      8999\n",
      "\n",
      "    accuracy                           0.46     27001\n",
      "   macro avg       0.61      0.46      0.44     27001\n",
      "weighted avg       0.61      0.46      0.44     27001\n",
      "\n",
      "Performed in 5.663975300005404\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.41      0.72      0.52      8957\n",
      "    negative       0.70      0.42      0.52      9045\n",
      "    positive       0.72      0.48      0.57      8999\n",
      "\n",
      "    accuracy                           0.54     27001\n",
      "   macro avg       0.61      0.54      0.54     27001\n",
      "weighted avg       0.61      0.54      0.54     27001\n",
      "\n",
      "Performed in 6.065098199993372\n",
      "min_df: 0; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.42      0.70      0.52      8957\n",
      "    negative       0.69      0.45      0.54      9045\n",
      "    positive       0.72      0.51      0.60      8999\n",
      "\n",
      "    accuracy                           0.55     27001\n",
      "   macro avg       0.61      0.55      0.55     27001\n",
      "weighted avg       0.61      0.55      0.55     27001\n",
      "\n",
      "Performed in 6.1785875000059605\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.35      0.91      0.50      8957\n",
      "    negative       0.76      0.16      0.27      9045\n",
      "    positive       0.62      0.11      0.18      8999\n",
      "\n",
      "    accuracy                           0.39     27001\n",
      "   macro avg       0.58      0.40      0.32     27001\n",
      "weighted avg       0.58      0.39      0.32     27001\n",
      "\n",
      "Performed in 5.8351893999788444\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.35      0.91      0.50      8957\n",
      "    negative       0.76      0.16      0.27      9045\n",
      "    positive       0.62      0.11      0.18      8999\n",
      "\n",
      "    accuracy                           0.39     27001\n",
      "   macro avg       0.58      0.40      0.32     27001\n",
      "weighted avg       0.58      0.39      0.32     27001\n",
      "\n",
      "Performed in 5.730980599997565\n",
      "min_df: 0.001; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.35      0.91      0.50      8957\n",
      "    negative       0.76      0.16      0.27      9045\n",
      "    positive       0.62      0.11      0.18      8999\n",
      "\n",
      "    accuracy                           0.39     27001\n",
      "   macro avg       0.58      0.40      0.32     27001\n",
      "weighted avg       0.58      0.39      0.32     27001\n",
      "\n",
      "Performed in 5.37902690001647\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.00      0.00      0.00      9045\n",
      "    positive       0.06      0.00      0.00      8999\n",
      "\n",
      "    accuracy                           0.33     27001\n",
      "   macro avg       0.13      0.33      0.17     27001\n",
      "weighted avg       0.13      0.33      0.17     27001\n",
      "\n",
      "Performed in 5.2967622000142\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.00      0.00      0.00      9045\n",
      "    positive       0.06      0.00      0.00      8999\n",
      "\n",
      "    accuracy                           0.33     27001\n",
      "   macro avg       0.13      0.33      0.17     27001\n",
      "weighted avg       0.13      0.33      0.17     27001\n",
      "\n",
      "Performed in 5.424715100001777\n",
      "min_df: 0.01; max_df: 0.5\n",
      "ngram_range: (3, 3)\n",
      "analyzer: word\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.33      0.99      0.50      8957\n",
      "    negative       0.00      0.00      0.00      9045\n",
      "    positive       0.06      0.00      0.00      8999\n",
      "\n",
      "    accuracy                           0.33     27001\n",
      "   macro avg       0.13      0.33      0.17     27001\n",
      "weighted avg       0.13      0.33      0.17     27001\n",
      "\n",
      "Performed in 5.029545600002166\n"
     ]
    }
   ],
   "source": [
    "MIN_NGRAM = 2\n",
    "MAX_NGRAM = 4\n",
    "\n",
    "for min_n in range(MIN_NGRAM, MAX_NGRAM):\n",
    "    for max_n in range(min_n, MAX_NGRAM):\n",
    "        for max_df in [0.1, 0.5]:\n",
    "            for min_df in [0, 0.001, 0.01]:\n",
    "                for max_features in [1000, 25000, 50000]:\n",
    "                    print(f\"min_df: {min_df}; max_df: {max_df}\")\n",
    "                    naive_bayes_classifier(TfidfVectorizer(ngram_range=(min_n, max_n), max_df=max_df, min_df=min_df, max_features=max_features, stop_words=stopwords.words('russian')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range: (2, 2)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.52      0.63      0.57      8957\n",
      "    negative       0.68      0.56      0.62      9045\n",
      "    positive       0.75      0.74      0.75      8999\n",
      "\n",
      "    accuracy                           0.64     27001\n",
      "   macro avg       0.65      0.64      0.64     27001\n",
      "weighted avg       0.65      0.64      0.64     27001\n",
      "\n",
      "Performed in 6.946093299979111\n",
      "ngram_range: (2, 3)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.55      0.67      0.61      8957\n",
      "    negative       0.71      0.58      0.64      9045\n",
      "    positive       0.81      0.78      0.80      8999\n",
      "\n",
      "    accuracy                           0.68     27001\n",
      "   macro avg       0.69      0.68      0.68     27001\n",
      "weighted avg       0.69      0.68      0.68     27001\n",
      "\n",
      "Performed in 14.077155300008599\n",
      "ngram_range: (2, 4)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.69      0.62      8957\n",
      "    negative       0.72      0.59      0.65      9045\n",
      "    positive       0.84      0.80      0.82      8999\n",
      "\n",
      "    accuracy                           0.69     27001\n",
      "   macro avg       0.71      0.69      0.70     27001\n",
      "weighted avg       0.71      0.69      0.70     27001\n",
      "\n",
      "Performed in 22.05146690001129\n",
      "ngram_range: (2, 5)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.57      0.70      0.63      8957\n",
      "    negative       0.73      0.60      0.66      9045\n",
      "    positive       0.85      0.82      0.83      8999\n",
      "\n",
      "    accuracy                           0.70     27001\n",
      "   macro avg       0.72      0.70      0.71     27001\n",
      "weighted avg       0.72      0.70      0.71     27001\n",
      "\n",
      "Performed in 28.172086600010516\n",
      "ngram_range: (2, 6)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.58      0.70      0.63      8957\n",
      "    negative       0.73      0.61      0.66      9045\n",
      "    positive       0.86      0.82      0.84      8999\n",
      "\n",
      "    accuracy                           0.71     27001\n",
      "   macro avg       0.72      0.71      0.71     27001\n",
      "weighted avg       0.72      0.71      0.71     27001\n",
      "\n",
      "Performed in 42.30654499999946\n",
      "ngram_range: (2, 7)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.58      0.70      0.64      8957\n",
      "    negative       0.73      0.62      0.67      9045\n",
      "    positive       0.86      0.83      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.72     27001\n",
      "weighted avg       0.73      0.72      0.72     27001\n",
      "\n",
      "Performed in 57.09721099998569\n",
      "ngram_range: (3, 3)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.56      0.68      0.61      8957\n",
      "    negative       0.72      0.59      0.65      9045\n",
      "    positive       0.83      0.79      0.81      8999\n",
      "\n",
      "    accuracy                           0.69     27001\n",
      "   macro avg       0.70      0.69      0.69     27001\n",
      "weighted avg       0.70      0.69      0.69     27001\n",
      "\n",
      "Performed in 7.450756399979582\n",
      "ngram_range: (3, 4)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.57      0.69      0.62      8957\n",
      "    negative       0.72      0.60      0.65      9045\n",
      "    positive       0.84      0.81      0.82      8999\n",
      "\n",
      "    accuracy                           0.70     27001\n",
      "   macro avg       0.71      0.70      0.70     27001\n",
      "weighted avg       0.71      0.70      0.70     27001\n",
      "\n",
      "Performed in 14.881331499986118\n",
      "ngram_range: (3, 5)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.57      0.70      0.63      8957\n",
      "    negative       0.73      0.60      0.66      9045\n",
      "    positive       0.85      0.82      0.84      8999\n",
      "\n",
      "    accuracy                           0.71     27001\n",
      "   macro avg       0.72      0.71      0.71     27001\n",
      "weighted avg       0.72      0.71      0.71     27001\n",
      "\n",
      "Performed in 23.384334700007457\n",
      "ngram_range: (3, 6)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.58      0.70      0.63      8957\n",
      "    negative       0.73      0.61      0.67      9045\n",
      "    positive       0.86      0.83      0.84      8999\n",
      "\n",
      "    accuracy                           0.71     27001\n",
      "   macro avg       0.72      0.71      0.71     27001\n",
      "weighted avg       0.72      0.71      0.71     27001\n",
      "\n",
      "Performed in 33.88142349998816\n",
      "ngram_range: (3, 7)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.58      0.70      0.64      8957\n",
      "    negative       0.73      0.62      0.67      9045\n",
      "    positive       0.86      0.83      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.72     27001\n",
      "weighted avg       0.73      0.72      0.72     27001\n",
      "\n",
      "Performed in 50.25947789999191\n",
      "ngram_range: (4, 4)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.57      0.69      0.62      8957\n",
      "    negative       0.73      0.60      0.66      9045\n",
      "    positive       0.84      0.82      0.83      8999\n",
      "\n",
      "    accuracy                           0.70     27001\n",
      "   macro avg       0.71      0.70      0.70     27001\n",
      "weighted avg       0.71      0.70      0.70     27001\n",
      "\n",
      "Performed in 8.067559700022684\n",
      "ngram_range: (4, 5)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.58      0.70      0.63      8957\n",
      "    negative       0.73      0.61      0.66      9045\n",
      "    positive       0.85      0.83      0.84      8999\n",
      "\n",
      "    accuracy                           0.71     27001\n",
      "   macro avg       0.72      0.71      0.71     27001\n",
      "weighted avg       0.72      0.71      0.71     27001\n",
      "\n",
      "Performed in 18.99081409999053\n",
      "ngram_range: (4, 6)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.58      0.70      0.64      8957\n",
      "    negative       0.74      0.61      0.67      9045\n",
      "    positive       0.86      0.83      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.72     27001\n",
      "weighted avg       0.73      0.72      0.72     27001\n",
      "\n",
      "Performed in 31.008217399998102\n",
      "ngram_range: (4, 7)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.59      0.70      0.64      8957\n",
      "    negative       0.74      0.62      0.67      9045\n",
      "    positive       0.87      0.84      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.72     27001\n",
      "weighted avg       0.73      0.72      0.72     27001\n",
      "\n",
      "Performed in 41.23174590000417\n",
      "ngram_range: (5, 5)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.58      0.70      0.64      8957\n",
      "    negative       0.74      0.61      0.67      9045\n",
      "    positive       0.86      0.83      0.84      8999\n",
      "\n",
      "    accuracy                           0.71     27001\n",
      "   macro avg       0.73      0.71      0.72     27001\n",
      "weighted avg       0.73      0.71      0.72     27001\n",
      "\n",
      "Performed in 10.125660899997456\n",
      "ngram_range: (5, 6)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.59      0.70      0.64      8957\n",
      "    negative       0.74      0.62      0.67      9045\n",
      "    positive       0.86      0.84      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.72     27001\n",
      "weighted avg       0.73      0.72      0.72     27001\n",
      "\n",
      "Performed in 20.09401629999047\n",
      "ngram_range: (5, 7)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.59      0.70      0.64      8957\n",
      "    negative       0.74      0.63      0.68      9045\n",
      "    positive       0.87      0.84      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.72     27001\n",
      "weighted avg       0.73      0.72      0.72     27001\n",
      "\n",
      "Performed in 30.843331600015517\n",
      "ngram_range: (6, 6)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.59      0.70      0.64      8957\n",
      "    negative       0.74      0.62      0.68      9045\n",
      "    positive       0.87      0.83      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.72     27001\n",
      "weighted avg       0.73      0.72      0.72     27001\n",
      "\n",
      "Performed in 11.202195299993036\n",
      "ngram_range: (6, 7)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.59      0.70      0.64      8957\n",
      "    negative       0.74      0.63      0.68      9045\n",
      "    positive       0.87      0.84      0.85      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.73     27001\n",
      "weighted avg       0.73      0.72      0.73     27001\n",
      "\n",
      "Performed in 22.993822299991734\n",
      "ngram_range: (7, 7)\n",
      "analyzer: char\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    neautral       0.59      0.70      0.64      8957\n",
      "    negative       0.74      0.64      0.68      9045\n",
      "    positive       0.87      0.84      0.86      8999\n",
      "\n",
      "    accuracy                           0.72     27001\n",
      "   macro avg       0.73      0.72      0.73     27001\n",
      "weighted avg       0.73      0.72      0.73     27001\n",
      "\n",
      "Performed in 12.31623200001195\n"
     ]
    }
   ],
   "source": [
    "MIN_NGRAM = 2\n",
    "MAX_NGRAM = 8\n",
    "\n",
    "for min_n in range(MIN_NGRAM, MAX_NGRAM):\n",
    "    for max_n in range(min_n, MAX_NGRAM):\n",
    "        naive_bayes_classifier(CountVectorizer(ngram_range=(min_n, max_n), analyzer='char', stop_words=stopwords.words('russian')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "           Vectorizer Analyzer       Parameters  Precision    Recall  F1-Score\n95  CountVectorizer'>     char  [ngram: (7, 7)]   0.734288  0.724714  0.726855\n94  CountVectorizer'>     char  [ngram: (6, 7)]   0.733887  0.723381  0.725638\n92  CountVectorizer'>     char  [ngram: (5, 7)]   0.732996  0.722788  0.724822\n89  CountVectorizer'>     char  [ngram: (4, 7)]   0.730700  0.720084  0.722148\n93  CountVectorizer'>     char  [ngram: (6, 6)]   0.731067  0.719751  0.722070\n91  CountVectorizer'>     char  [ngram: (5, 6)]   0.729323  0.718455  0.720479\n85  CountVectorizer'>     char  [ngram: (3, 7)]   0.727638  0.716492  0.718624\n80  CountVectorizer'>     char  [ngram: (2, 7)]   0.727050  0.715640  0.717819\n88  CountVectorizer'>     char  [ngram: (4, 6)]   0.726779  0.715159  0.717280\n90  CountVectorizer'>     char  [ngram: (5, 5)]   0.725791  0.714085  0.716172",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Vectorizer</th>\n      <th>Analyzer</th>\n      <th>Parameters</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1-Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>95</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (7, 7)]</td>\n      <td>0.734288</td>\n      <td>0.724714</td>\n      <td>0.726855</td>\n    </tr>\n    <tr>\n      <th>94</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (6, 7)]</td>\n      <td>0.733887</td>\n      <td>0.723381</td>\n      <td>0.725638</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (5, 7)]</td>\n      <td>0.732996</td>\n      <td>0.722788</td>\n      <td>0.724822</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (4, 7)]</td>\n      <td>0.730700</td>\n      <td>0.720084</td>\n      <td>0.722148</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (6, 6)]</td>\n      <td>0.731067</td>\n      <td>0.719751</td>\n      <td>0.722070</td>\n    </tr>\n    <tr>\n      <th>91</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (5, 6)]</td>\n      <td>0.729323</td>\n      <td>0.718455</td>\n      <td>0.720479</td>\n    </tr>\n    <tr>\n      <th>85</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (3, 7)]</td>\n      <td>0.727638</td>\n      <td>0.716492</td>\n      <td>0.718624</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (2, 7)]</td>\n      <td>0.727050</td>\n      <td>0.715640</td>\n      <td>0.717819</td>\n    </tr>\n    <tr>\n      <th>88</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (4, 6)]</td>\n      <td>0.726779</td>\n      <td>0.715159</td>\n      <td>0.717280</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>CountVectorizer'&gt;</td>\n      <td>char</td>\n      <td>[ngram: (5, 5)]</td>\n      <td>0.725791</td>\n      <td>0.714085</td>\n      <td>0.716172</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = []\n",
    "for result, vectorizer in results:\n",
    "    score = result[\"weighted avg\"]\n",
    "    params = []\n",
    "    if isinstance(vectorizer, TfidfVectorizer):\n",
    "        params.append(f\"min_df: {vectorizer.min_df} max_df: {vectorizer.max_df} max_features: {vectorizer.max_features}\")\n",
    "    params.append(f\"ngram: {vectorizer.ngram_range}\")\n",
    "    raw_data.append({\"Vectorizer\": str(type(vectorizer)).split('.')[-1], \"Analyzer\": vectorizer.analyzer, \"Parameters\": params, \"Precision\": score[\"precision\"], \"Recall\": score[\"recall\"], \"F1-Score\": score[\"f1-score\"]})\n",
    "data_result = pd.DataFrame(raw_data)\n",
    "data_result.sort_values(by=[\"F1-Score\"], ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "По результатам видно, что лучшим векторайзером оказались символьные n-граммы.\n",
    "Лучшими параметрами для tf-idf оказались min_df: 0 max_df: 0.1 max_features: 50000, ngram: (2, 2)\n",
    "Для мешка n-грамм: ngram: (2, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QYTwyMtWhAZ"
   },
   "source": [
    "## Задание 5.2 Регулярные выражения\n",
    "\n",
    "Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах. \n",
    "\n",
    "Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
    "\n",
    "Навык полезный, давайте в нём тоже потренируемся.\n",
    "\n",
    "Для работы с регулярными выражениями есть библиотека **re**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VaUW5S4gWhAb"
   },
   "source": [
    "import re"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6aYh7Osl8xr"
   },
   "source": [
    "В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n",
    "* **а?** - ноль или один символ **а**\n",
    "* **а+** - один или более символов **а**\n",
    "* **а\\*** - ноль или более символов **а** (не путать с +)\n",
    "* **.** - любое количество любого символа\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result = re.findall('a?b.', 'aabbсabbcbb')\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o0Wh4EZcUVWB",
    "outputId": "eb3baf5e-4bf5-4e32-e9c0-b08fab66ba7c"
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abb', 'abb', 'bb']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result = re.findall('a*b.', 'aabbсabbcbb')\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZgN7gjUwWGON",
    "outputId": "4c7da339-1c1d-464d-e958-18f091f3c1b0"
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aabb', 'abb', 'bb']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "result = re.findall('a+b.', 'aabbсabbcbb')\n",
    "print(result)"
   ],
   "metadata": {
    "id": "izXJKMwJWKyY",
    "outputId": "358233f6-4a73-4e40-b797-b2d4aed3acd1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aabb', 'abb']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7zOFFA3l_KQ"
   },
   "source": [
    "Рассмотрим подробно несколько наиболее полезных функций:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbJrUpARWhAd"
   },
   "source": [
    "### findall\n",
    "возвращает список всех найденных непересекающихся совпадений.\n",
    "\n",
    "Регулярное выражение **ab+c.**: \n",
    "* **a** - просто символ **a**\n",
    "* **b+** - один или более символов **b**\n",
    "* **c** - просто символ **c**\n",
    "* **.** - любой символ\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2athHzKuWhAd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cafee36f-540d-4206-a320-d98ae94c4c47"
   },
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc')\n",
    "print(result)"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abca']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9FpIw5RWhAf"
   },
   "source": [
    "Вопрос на внимательность: почему нет abcx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5ttzoxEWhAg"
   },
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7ZR2AEq3WhAg"
   },
   "source": [
    "result = re.findall(r'\\b\\w{2}', \"Mauris id augue ac risus convallis laoreet a eu tellus\")\n",
    "print(result)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ma', 'id', 'au', 'ac', 'ri', 'co', 'la', 'eu', 'te']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI18l-l9WhAk"
   },
   "source": [
    "### split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sVKdRoc1WhAl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "78b5d289-8e8c-4621-fe3c-34aa130c727c"
   },
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie')\n",
    "print(result)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10u5efuSWhAm"
   },
   "source": [
    "можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9U9EQZMwWhAn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "45699604-9950-4185-cd4f-0e3ad6655629"
   },
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=2)\n",
    "print(result)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie, weenie']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EMcMyflWhAp"
   },
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dVgPSjEOWhAp"
   },
   "source": [
    "result = re.split('\\.',\n",
    "                  'Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque tincidunt ac nulla sed pellentesque. Fusce non pellentesque elit, ac viverra est. Maecenas laoreet, leo eget venenatis dictum, nisi eros vestibulum sem, nec tristique est risus et lorem. Cras faucibus lorem ante, sed volutpat est hendrerit fermentum. Vestibulum aliquam non lectus eu blandit. Nam suscipit lacus id sollicitudin aliquam. Etiam ut ultricies mauris.',\n",
    "                  maxsplit=2)\n",
    "print(result)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem ipsum dolor sit amet, consectetur adipiscing elit', ' Pellentesque tincidunt ac nulla sed pellentesque', ' Fusce non pellentesque elit, ac viverra est. Maecenas laoreet, leo eget venenatis dictum, nisi eros vestibulum sem, nec tristique est risus et lorem. Cras faucibus lorem ante, sed volutpat est hendrerit fermentum. Vestibulum aliquam non lectus eu blandit. Nam suscipit lacus id sollicitudin aliquam. Etiam ut ultricies mauris.']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wrEGqBSWhAr"
   },
   "source": [
    "### sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "az3KxKWwWhAr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "93f260be-ce79-405c-b21a-5ca8345ff4b7"
   },
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print(result)"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbcbbc\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qD0n7_HPWhAt"
   },
   "source": [
    "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s_Sdu7xlWhAu"
   },
   "source": [
    "result = re.sub(r'\\d', 'DIG', '1 one 2 two 3 three 4 four 10 ten')\n",
    "print(result)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIG one DIG two DIG three DIG four DIGDIG ten\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8__oi1PWhAv"
   },
   "source": [
    "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KwNS9zt4WhAv"
   },
   "source": [
    "result = re.sub(r'\\w+://\\S+', '[link removed]',\n",
    "                'Docs: https://docs.python.org/3/library/re.html Meme: https://www.youtube.com/watch?v=dQw4w9WgXcQ&t=0s')\n",
    "print(result)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: [link removed] Meme: [link removed]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gStgBJy2WhAx"
   },
   "source": [
    "### compile\n",
    "компилирует регулярное выражение в отдельный объект"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JstTupisWhAy",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f60e13a6-9d93-46e5-f329-620f6072715f"
   },
   "source": [
    "# Пример: построение списка всех слов строки:\n",
    "prog = re.compile('[А-Яа-яё\\-]+')\n",
    "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXEXc3G0WhA2"
   },
   "source": [
    "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nFvnIWbUWhA2"
   },
   "source": [
    "rg = re.compile('\\w{4,}')\n",
    "rg.findall(\"Vestibulum pellentesque facilisis orci, id convallis dui vulputate id.\")"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "['Vestibulum', 'pellentesque', 'facilisis', 'orci', 'convallis', 'vulputate']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQDNZ3HQWhA3"
   },
   "source": [
    "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
    "\n",
    "```\n",
    "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "['@gmail.com', '@test.in', '@analyticsvidhya.com', '@rest.biz']"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'@[\\w.]+', 'abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
